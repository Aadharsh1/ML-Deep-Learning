{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RizwanMunawar/yolov7-pose-estimation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS6dzG9_j1Ni",
        "outputId": "254bc9c1-5582-4c42-a899-2805f611143b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7-pose-estimation'...\n",
            "remote: Enumerating objects: 193, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 193 (delta 42), reused 32 (delta 32), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (193/193), 3.75 MiB | 8.35 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd yolov7-pose-estimation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEeqBR9Ej2ue",
        "outputId": "87a38527-1c48-4ae0-d78c-ba17665caf30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7-pose-estimation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9BOKhY-j4LZ",
        "outputId": "45a3cee8-0307-4889-ec20-ecae0bf1af73"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXaNgTWSj6Ql",
        "outputId": "3b80c036-365d-4457-eabe-a9a1d8c0e472"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.4)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.15.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.13.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (5.9.5)\n",
            "Collecting thop (from -r requirements.txt (line 28))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2024.1)\n",
            "Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 26))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (4.9.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 26)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 26)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 26)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "Successfully installed jedi-0.19.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTANT. After running the above cells. Replace the pose-estimate.py with the following scripts based on whether you want to do pose estimation for images or for videos."
      ],
      "metadata": {
        "id": "9PXSSRSBhVjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For image\n"
      ],
      "metadata": {
        "id": "naQx6A2mhq_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from utils.datasets import letterbox\n",
        "from utils.torch_utils import select_device\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import non_max_suppression_kpt,strip_optimizer,xyxy2xywh\n",
        "from utils.plots import output_to_keypoint, plot_skeleton_kpts,colors,plot_one_box_kpt\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run(poseweights=\"yolov7-w6-pose.pt\", source='rugby.jpg', device='cpu', view_img=False):\n",
        "    print(source)\n",
        "    device = select_device(device)  # Select device\n",
        "    model = attempt_load(poseweights, map_location=device)  # Load model\n",
        "    _ = model.eval()\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names  # Get class names\n",
        "\n",
        "    # Read image\n",
        "    orig_image = cv2.imread(source)\n",
        "    if orig_image is None:\n",
        "        print('Error while trying to read image. Please check path again')\n",
        "        raise SystemExit()\n",
        "\n",
        "    def letterbox1(image, new_shape=(640, 640), color=(0, 0, 0), stride=32, auto=False):\n",
        "\n",
        "      height, width = image.shape[:2]\n",
        "      new_width, new_height = new_shape\n",
        "      scale = min(new_height / height, new_width / width)\n",
        "      nw, nh = int(scale * width), int(scale * height)\n",
        "      image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "      top = (new_height - nh) // 2\n",
        "      bottom = new_height - nh - top\n",
        "      left = (new_width - nw) // 2\n",
        "      right = new_width - nw - left\n",
        "\n",
        "      image_padded = cv2.copyMakeBorder(image_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "      return image_padded\n",
        "\n",
        "\n",
        "    image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
        "    image = letterbox1(image, new_shape=(640, 640), stride=64, auto=True)\n",
        "    image_ = image.copy()\n",
        "    image = transforms.ToTensor()(image)\n",
        "    image = torch.tensor(np.array([image.numpy()]))\n",
        "\n",
        "    image = image.to(device)\n",
        "    image = image.float()\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        output_data, _ = model(image)\n",
        "\n",
        "    output_data = non_max_suppression_kpt(output_data,\n",
        "                                          0.25,  # Conf. Threshold.\n",
        "                                          0.65,  # IoU Threshold.\n",
        "                                          nc=model.yaml['nc'],  # Number of classes.\n",
        "                                          nkpt=model.yaml['nkpt'],  # Number of keypoints.\n",
        "                                          kpt_label=True)\n",
        "\n",
        "    # Draw keypoints\n",
        "    im0 = image[0].permute(1, 2, 0) * 255\n",
        "    im0 = im0.cpu().numpy().astype(np.uint8)\n",
        "    im0 = cv2.cvtColor(im0, cv2.COLOR_RGB2BGR)\n",
        "    im0_kpts = np.zeros((640, 640, 3), dtype=np.uint8)\n",
        "\n",
        "    def plot_keypoints_only(image, keypoints, color, line_thickness=2):\n",
        "      if keypoints is not None:\n",
        "          for kpt in keypoints:\n",
        "              # Example: Draw each keypoint\n",
        "              cv2.circle(image, (int(kpt[0]), int(kpt[1])), 3, color, -1)  # Draw keypoints\n",
        "          # Optionally, add connections between keypoints if needed\n",
        "          # This part would depend on the structure of your keypoints and the specific connections you want to show\n",
        "\n",
        "    for pose in output_data:\n",
        "        if len(pose):\n",
        "            for det, (*xyxy, conf, cls) in enumerate(pose):\n",
        "                c = int(cls)\n",
        "                kpts = pose[det, 6:]\n",
        "                # label = f'{names[c]} {conf:.2f}' # use this if u want bounding box, and conf, but label=label in plot func below\n",
        "                plot_one_box_kpt(xyxy, im0, color=colors(c, True),\n",
        "                                 line_thickness=3, kpt_label=True, kpts=kpts, steps=3,\n",
        "                                 orig_shape=im0.shape[:2])\n",
        "\n",
        "                plot_one_box_kpt(xyxy, im0_kpts, color=colors(c, True),\n",
        "                                 line_thickness=3, kpt_label=True, kpts=kpts, steps=3,\n",
        "                                 orig_shape=im0.shape[:2])\n",
        "\n",
        "\n",
        "\n",
        "    output_filename = f\"{source.split('.')[0]}_keypoint.jpg\"\n",
        "    cv2.imwrite(output_filename, im0)\n",
        "    print(f\"Output saved as {output_filename}\")\n",
        "\n",
        "    output_filename_kpts = f\"{source.split('.')[0]}_keypoints_only.jpg\"\n",
        "    cv2.imwrite(output_filename_kpts, im0_kpts)\n",
        "    print(f\"Keypoints only output saved as {output_filename_kpts}\")\n",
        "\n",
        "    if view_img:\n",
        "      cv2.imshow(\"Pose Estimation Result\", im0)\n",
        "      cv2.waitKey(0)\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "import argparse\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Run pose estimation on an image.\")\n",
        "    parser.add_argument('--source', type=str, default='rugby.jpg', help='Path to the image file')\n",
        "    parser.add_argument('--device', type=str, default='cpu', help='Device to run the model on')\n",
        "    parser.add_argument('--poseweights', type=str, default='yolov7-w6-pose.pt', help='Path to model weights')\n",
        "    parser.add_argument('--view-img', action='store_true', help='Display the result image if specified')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    run(poseweights=args.poseweights, source=args.source, device=args.device, view_img=args.view_img)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "zYlRGC2khs5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Video\n"
      ],
      "metadata": {
        "id": "OqYk_Rl3h67a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from utils.datasets import letterbox\n",
        "from utils.torch_utils import select_device\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import non_max_suppression_kpt,strip_optimizer,xyxy2xywh\n",
        "from utils.plots import output_to_keypoint, plot_skeleton_kpts,colors,plot_one_box_kpt\n",
        "\n",
        "@torch.no_grad()\n",
        "def run(poseweights=\"yolov7-w6-pose.pt\",source=\"football1.mp4\",device='cpu',view_img=False,\n",
        "        save_conf=False,line_thickness = 3,hide_labels=False, hide_conf=True):\n",
        "\n",
        "    frame_count = 0  #count no of frames\n",
        "    total_fps = 0  #count total fps\n",
        "    time_list = []   #list to store time\n",
        "    fps_list = []    #list to store fps\n",
        "\n",
        "    device = select_device(opt.device) #select device\n",
        "    half = device.type != 'cpu'\n",
        "\n",
        "    model = attempt_load(poseweights, map_location=device)  #Load model\n",
        "    _ = model.eval()\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names  # get class names\n",
        "\n",
        "    if source.isnumeric() :\n",
        "        cap = cv2.VideoCapture(int(source))    #pass video to videocapture object\n",
        "    else :\n",
        "        cap = cv2.VideoCapture(source)    #pass video to videocapture object\n",
        "\n",
        "    if (cap.isOpened() == False):   #check if videocapture not opened\n",
        "        print('Error while trying to read video. Please check path again')\n",
        "        raise SystemExit()\n",
        "\n",
        "    else:\n",
        "        frame_width = int(cap.get(3))  #get video frame width\n",
        "        frame_height = int(cap.get(4)) #get video frame height\n",
        "        def letterbox1(image, new_shape=(640, 640), color=(0, 0, 0), stride=32, auto=False):\n",
        "          height, width = image.shape[:2]\n",
        "          new_width, new_height = new_shape\n",
        "          scale = min(new_height / height, new_width / width)\n",
        "          nw, nh = int(scale * width), int(scale * height)\n",
        "          image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "          top = (new_height - nh) // 2\n",
        "          bottom = new_height - nh - top\n",
        "          left = (new_width - nw) // 2\n",
        "          right = new_width - nw - left\n",
        "\n",
        "          image_padded = cv2.copyMakeBorder(image_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "          return image_padded\n",
        "\n",
        "        vid_write_image = letterbox1(cap.read()[1], new_shape=(640, 640), stride=64, auto=True) #init videowriter\n",
        "        out_video_name = f\"{source.split('/')[-1].split('.')[0]}\"\n",
        "        out = cv2.VideoWriter(f\"{source}_keypoint.mp4\",\n",
        "                            cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
        "                            (640, 640))\n",
        "\n",
        "        out_kpts = cv2.VideoWriter(f\"{out_video_name}_keypoints_only.mp4\",\n",
        "                           cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
        "                           (640, 640))\n",
        "\n",
        "        while(cap.isOpened): #loop until cap opened or video not complete\n",
        "\n",
        "            print(\"Frame {} Processing\".format(frame_count+1))\n",
        "\n",
        "            ret, frame = cap.read()  #get frame and success from video capture\n",
        "\n",
        "            if ret: #if success is true, means frame exist\n",
        "                orig_image = frame #store frame\n",
        "                image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB) #convert frame to RGB\n",
        "                image = letterbox1(image, new_shape=(640, 640), stride=64, auto=True)\n",
        "                image_ = image.copy()\n",
        "                image = transforms.ToTensor()(image)\n",
        "                image = torch.tensor(np.array([image.numpy()]))\n",
        "\n",
        "                image = image.to(device)  #convert image data to device\n",
        "                image = image.float() #convert image to float precision (cpu)\n",
        "                start_time = time.time() #start time for fps calculation\n",
        "\n",
        "                with torch.no_grad():  #get predictions\n",
        "                    output_data, _ = model(image)\n",
        "\n",
        "                output_data = non_max_suppression_kpt(output_data,   #Apply non max suppression\n",
        "                                            0.25,   # Conf. Threshold.\n",
        "                                            0.65, # IoU Threshold.\n",
        "                                            nc=model.yaml['nc'], # Number of classes.\n",
        "                                            nkpt=model.yaml['nkpt'], # Number of keypoints.\n",
        "                                            kpt_label=True)\n",
        "\n",
        "                output = output_to_keypoint(output_data)\n",
        "\n",
        "                im0 = image[0].permute(1, 2, 0) * 255 # Change format [b, c, h, w] to [h, w, c] for displaying the image.\n",
        "                im0 = im0.cpu().numpy().astype(np.uint8)\n",
        "\n",
        "                im0 = cv2.cvtColor(im0, cv2.COLOR_RGB2BGR) #reshape image format to (BGR)\n",
        "                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "                im0_kpts = np.zeros((640, 640, 3), dtype=np.uint8)\n",
        "                for i, pose in enumerate(output_data):  # detections per image\n",
        "\n",
        "                    if len(output_data):  #check if no pose\n",
        "                        for c in pose[:, 5].unique(): # Print results\n",
        "                            n = (pose[:, 5] == c).sum()  # detections per class\n",
        "                            print(\"No of Objects in Current Frame : {}\".format(n))\n",
        "\n",
        "                        for det_index, (*xyxy, conf, cls) in enumerate(reversed(pose[:,:6])): #loop over poses for drawing on frame\n",
        "                            c = int(cls)  # integer class\n",
        "                            kpts = pose[det_index, 6:]\n",
        "                            # label = None if opt.hide_labels else (names[c] if opt.hide_conf else f'{names[c]} {conf:.2f}')\n",
        "                            # put label = label if want see conf level\n",
        "                            plot_one_box_kpt(xyxy, im0, color=colors(c, True),\n",
        "                                        line_thickness=opt.line_thickness,kpt_label=True, kpts=kpts, steps=3,\n",
        "                                        orig_shape=im0.shape[:2])\n",
        "                            plot_one_box_kpt(xyxy, im0_kpts, color=colors(c, True),\n",
        "                                        line_thickness=opt.line_thickness,kpt_label=True, kpts=kpts, steps=3,\n",
        "                                        orig_shape=im0.shape[:2])\n",
        "\n",
        "\n",
        "                end_time = time.time()  #Calculatio for FPS\n",
        "                fps = 1 / (end_time - start_time)\n",
        "                total_fps += fps\n",
        "                frame_count += 1\n",
        "\n",
        "                fps_list.append(total_fps) #append FPS in list\n",
        "                time_list.append(end_time - start_time) #append time in list\n",
        "\n",
        "                # Stream results\n",
        "                if view_img:\n",
        "                    cv2.imshow(\"YOLOv7 Pose Estimation Demo\", im0)\n",
        "                    cv2.waitKey(1)  # 1 millisecond\n",
        "\n",
        "                out.write(im0)  #writing the video frame\n",
        "                out_kpts.write(im0_kpts)\n",
        "\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        out.release()  # Release the main video writer\n",
        "        out_kpts.release()\n",
        "        # cv2.destroyAllWindows()\n",
        "        avg_fps = total_fps / frame_count\n",
        "        print(f\"Average FPS: {avg_fps:.3f}\")\n",
        "\n",
        "        #plot the comparision graph\n",
        "        plot_fps_time_comparision(time_list=time_list,fps_list=fps_list)\n",
        "\n",
        "\n",
        "def parse_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--poseweights', nargs='+', type=str, default='yolov7-w6-pose.pt', help='model path(s)')\n",
        "    parser.add_argument('--source', type=str, default='football1.mp4', help='video/0 for webcam') #video source\n",
        "    parser.add_argument('--device', type=str, default='cpu', help='cpu/0,1,2,3(gpu)')   #device arugments\n",
        "    parser.add_argument('--view-img', action='store_true', help='display results')  #display results\n",
        "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels') #save confidence in txt writing\n",
        "    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)') #box linethickness\n",
        "    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels') #box hidelabel\n",
        "    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences') #boxhideconf\n",
        "    opt = parser.parse_args()\n",
        "    return opt\n",
        "\n",
        "#function for plot fps and time comparision graph\n",
        "def plot_fps_time_comparision(time_list,fps_list):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('FPS')\n",
        "    plt.title('FPS and Time Comparision Graph')\n",
        "    plt.plot(time_list, fps_list,'b',label=\"FPS & Time\")\n",
        "    plt.savefig(\"FPS_and_Time_Comparision_pose_estimate.png\")\n",
        "\n",
        "\n",
        "#main function\n",
        "def main(opt):\n",
        "    run(**vars(opt))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    opt = parse_opt()\n",
        "    strip_optimizer(opt.device,opt.poseweights)\n",
        "    main(opt)"
      ],
      "metadata": {
        "id": "C7phb8hEh8go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download weights for pose estimation.\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z7Gv_F6j74A",
        "outputId": "f12199c6-ca58-41a4-c0aa-bd94a23f6907"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-15 09:40:27--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ad063dcb-fb9a-4511-b4d7-499601326cd8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240715%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240715T094028Z&X-Amz-Expires=300&X-Amz-Signature=85d644824768cbe41fa699fd659f64e47514241403c084f720246efb6c74d428&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-w6-pose.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-07-15 09:40:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ad063dcb-fb9a-4511-b4d7-499601326cd8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240715%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240715T094028Z&X-Amz-Expires=300&X-Amz-Signature=85d644824768cbe41fa699fd659f64e47514241403c084f720246efb6c74d428&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-w6-pose.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 161114789 (154M) [application/octet-stream]\n",
            "Saving to: ‘yolov7-w6-pose.pt’\n",
            "\n",
            "yolov7-w6-pose.pt   100%[===================>] 153.65M   429MB/s    in 0.4s    \n",
            "\n",
            "2024-07-15 09:40:28 (429 MB/s) - ‘yolov7-w6-pose.pt’ saved [161114789/161114789]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pose-estimate.py --source \"video_name.mp4\" --device 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMhk5AsykJXt",
        "outputId": "d96a38c5-d99e-4d78-c744-0ec7ec19e113"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer stripped from yolov7-w6-pose.pt, 161.1MB\n",
            "Fusing layers... \n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Frame 1 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 2 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 3 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 4 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 5 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 6 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 7 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 8 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 9 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 10 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 11 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 12 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 13 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 14 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 15 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 16 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 17 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 18 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 19 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 20 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 21 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 22 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 23 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 24 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 25 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 26 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 27 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 28 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 29 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 30 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 31 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 32 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 33 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 34 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 35 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 36 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 37 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 38 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 39 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 40 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 41 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 42 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 43 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 44 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 45 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 46 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 47 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 48 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 49 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 50 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 51 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 52 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 53 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 54 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 55 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 56 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 57 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 58 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 59 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 60 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 61 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 62 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 63 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 64 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 65 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 66 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 67 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 68 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 69 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 70 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 71 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 72 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 73 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 74 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 75 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 76 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 77 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 78 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 79 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 80 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 81 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 82 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 83 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 84 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 85 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 86 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 87 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 88 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 89 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 90 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 91 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 92 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 93 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 94 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 95 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 96 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 97 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 98 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 99 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 100 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 101 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 102 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 103 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 104 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 105 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 106 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 107 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 108 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 109 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 110 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 111 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 112 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 113 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 114 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 115 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 116 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 117 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 118 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 119 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 120 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 121 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 122 Processing\n",
            "No of Objects in Current Frame : 1\n",
            "Frame 123 Processing\n",
            "Average FPS: 27.235\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}